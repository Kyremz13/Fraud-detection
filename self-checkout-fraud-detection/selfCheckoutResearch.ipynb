{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9527448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7af113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159c2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_org = pd.read_csv('train.csv', delimiter='|')\n",
    "\n",
    "# uncomment the following to exclude records w/ trustlevel >=3 (done by Haritha).\n",
    "# Jonas: I think this is not the right way to simply exlcude them. The right way would be to tell a model it should\n",
    "# always predict no fraud when trustLevel >= 3. But I actually have no idea how to do this.\n",
    "\n",
    "#dataframe_org.drop(dataframe_org.loc[dataframe_org['trustLevel']>=3].index, inplace=True)\n",
    "\n",
    "dataframe = dataframe_org.copy()\n",
    "\n",
    "\n",
    "########### manual feature generation ##########\n",
    "\n",
    "# totalScanned:\n",
    "dataframe['totalScanned'] = dataframe['scannedLineItemsPerSecond'] * dataframe['totalScanTimeInSeconds']\n",
    "# avgValuePerScan:\n",
    "dataframe['avgTimePerScan'] = 1/ dataframe['scannedLineItemsPerSecond']\n",
    "dataframe['avgValuePerScan'] = dataframe['avgTimePerScan'] * dataframe['valuePerSecond']\n",
    "# manual feature generation - \"totalScanned\" ratios\n",
    "# withoutRegisPerPosition\n",
    "dataframe['withoutRegisPerPosition'] = dataframe['scansWithoutRegistration'] / dataframe['totalScanned']\n",
    "# ratio of scansWithoutRegis in totalScan\n",
    "# equivalent to lineItemVoidsPerPosition\n",
    "# Might indicate how new or ambivalent a customer is. Expected to be higher for low \"trustLevel\"\n",
    "# quantiModPerPosition\n",
    "dataframe['quantiModPerPosition'] = dataframe['quantityModifications'] / dataframe['totalScanned']\n",
    "# ratio of quanityMods in totalScan\n",
    "# manual feature generation - \"grandTotal\" ratios\n",
    "# lineItemVoidsPerTotal\n",
    "dataframe['lineItemVoidsPerTotal'] = dataframe['lineItemVoids'] / dataframe['grandTotal']\n",
    "# withoutRegisPerTotal\n",
    "dataframe['withoutRegisPerTotal'] = dataframe['scansWithoutRegistration'] / dataframe['grandTotal']\n",
    "# quantiModPerTotal\n",
    "dataframe['quantiModPerTotal'] = dataframe['quantityModifications'] / dataframe['grandTotal']\n",
    "# manual feature generation - \"totalScanTimeInSeconds\" ratios\n",
    "# lineItemVoidsPerTime\n",
    "dataframe['lineItemVoidsPerTime'] = dataframe['lineItemVoids'] / dataframe['totalScanTimeInSeconds']\n",
    "# withoutRegisPerTime\n",
    "dataframe['withoutRegisPerTime'] = dataframe['scansWithoutRegistration'] / dataframe['totalScanTimeInSeconds']\n",
    "# quantiModPerTime\n",
    "dataframe['quantiModPerTime'] = dataframe['quantityModifications'] / dataframe['totalScanTimeInSeconds']\n",
    "\n",
    "########### end manual feature generation ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2a28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base=dataframe.drop('fraud',axis=1)\n",
    "y_base=dataframe['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8209a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523b4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.preprocessing import StandardScaler\n",
    " sc=StandardScaler()\n",
    " X_base=sc.fit_transform(X_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42378a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "      <th>...</th>\n",
       "      <th>avgTimePerScan</th>\n",
       "      <th>avgValuePerScan</th>\n",
       "      <th>withoutRegisPerPosition</th>\n",
       "      <th>quantiModPerPosition</th>\n",
       "      <th>lineItemVoidsPerTotal</th>\n",
       "      <th>withoutRegisPerTotal</th>\n",
       "      <th>quantiModPerTotal</th>\n",
       "      <th>lineItemVoidsPerTime</th>\n",
       "      <th>withoutRegisPerTime</th>\n",
       "      <th>quantiModPerTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.344828</td>\n",
       "      <td>1.886207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.127971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>1.954286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.182749</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.146199</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>116.615385</td>\n",
       "      <td>4.781538</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>0.160875</td>\n",
       "      <td>0.080438</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.758621</td>\n",
       "      <td>3.183103</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.086665</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.002233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.925926</td>\n",
       "      <td>3.019630</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.024531</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.004651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>76.03</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071651</td>\n",
       "      <td>0.236854</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.956522</td>\n",
       "      <td>3.305652</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.105222</td>\n",
       "      <td>0.092069</td>\n",
       "      <td>0.026305</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1</td>\n",
       "      <td>397</td>\n",
       "      <td>41.89</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.269231</td>\n",
       "      <td>1.611154</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>4</td>\n",
       "      <td>316</td>\n",
       "      <td>41.83</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>0.132373</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.533333</td>\n",
       "      <td>1.394333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.119531</td>\n",
       "      <td>0.191250</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>2</td>\n",
       "      <td>685</td>\n",
       "      <td>62.68</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035036</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.541667</td>\n",
       "      <td>2.611667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>0.095724</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.002920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>4</td>\n",
       "      <td>1140</td>\n",
       "      <td>38.03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.001579</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.078885</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1879 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0              5                    1054       54.70              7   \n",
       "1              3                     108       27.36              5   \n",
       "2              3                    1516       62.16              3   \n",
       "3              6                    1791       92.31              8   \n",
       "4              5                     430       81.53              3   \n",
       "...          ...                     ...         ...            ...   \n",
       "1874           1                     321       76.03              8   \n",
       "1875           1                     397       41.89              5   \n",
       "1876           4                     316       41.83              5   \n",
       "1877           2                     685       62.68              1   \n",
       "1878           4                    1140       38.03              2   \n",
       "\n",
       "      scansWithoutRegistration  quantityModifications  \\\n",
       "0                            0                      3   \n",
       "1                            2                      4   \n",
       "2                           10                      5   \n",
       "3                            4                      4   \n",
       "4                            7                      2   \n",
       "...                        ...                    ...   \n",
       "1874                         7                      2   \n",
       "1875                         5                      0   \n",
       "1876                         8                      1   \n",
       "1877                         6                      2   \n",
       "1878                         2                      3   \n",
       "\n",
       "      scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "0                      0.027514        0.051898                  0.241379   \n",
       "1                      0.129630        0.253333                  0.357143   \n",
       "2                      0.008575        0.041003                  0.230769   \n",
       "3                      0.016192        0.051541                  0.275862   \n",
       "4                      0.062791        0.189605                  0.111111   \n",
       "...                         ...             ...                       ...   \n",
       "1874                   0.071651        0.236854                  0.347826   \n",
       "1875                   0.065491        0.105516                  0.192308   \n",
       "1876                   0.094937        0.132373                  0.166667   \n",
       "1877                   0.035036        0.091504                  0.041667   \n",
       "1878                   0.016667        0.033360                  0.105263   \n",
       "\n",
       "      fraud  ...  avgTimePerScan  avgValuePerScan  withoutRegisPerPosition  \\\n",
       "0         0  ...       36.344828         1.886207                 0.000000   \n",
       "1         0  ...        7.714286         1.954286                 0.142857   \n",
       "2         0  ...      116.615385         4.781538                 0.769231   \n",
       "3         0  ...       61.758621         3.183103                 0.137931   \n",
       "4         0  ...       15.925926         3.019630                 0.259259   \n",
       "...     ...  ...             ...              ...                      ...   \n",
       "1874      0  ...       13.956522         3.305652                 0.304348   \n",
       "1875      1  ...       15.269231         1.611154                 0.192308   \n",
       "1876      0  ...       10.533333         1.394333                 0.266667   \n",
       "1877      0  ...       28.541667         2.611667                 0.250000   \n",
       "1878      0  ...       60.000000         2.001579                 0.105263   \n",
       "\n",
       "      quantiModPerPosition  lineItemVoidsPerTotal  withoutRegisPerTotal  \\\n",
       "0                 0.103448               0.127971              0.000000   \n",
       "1                 0.285714               0.182749              0.073099   \n",
       "2                 0.384615               0.048263              0.160875   \n",
       "3                 0.137931               0.086665              0.043332   \n",
       "4                 0.074074               0.036796              0.085858   \n",
       "...                    ...                    ...                   ...   \n",
       "1874              0.086957               0.105222              0.092069   \n",
       "1875              0.000000               0.119360              0.119360   \n",
       "1876              0.033333               0.119531              0.191250   \n",
       "1877              0.083333               0.015954              0.095724   \n",
       "1878              0.157895               0.052590              0.052590   \n",
       "\n",
       "      quantiModPerTotal  lineItemVoidsPerTime  withoutRegisPerTime  \\\n",
       "0              0.054845              0.006641             0.000000   \n",
       "1              0.146199              0.046296             0.018519   \n",
       "2              0.080438              0.001979             0.006596   \n",
       "3              0.043332              0.004467             0.002233   \n",
       "4              0.024531              0.006977             0.016279   \n",
       "...                 ...                   ...                  ...   \n",
       "1874           0.026305              0.024922             0.021807   \n",
       "1875           0.000000              0.012594             0.012594   \n",
       "1876           0.023906              0.015823             0.025316   \n",
       "1877           0.031908              0.001460             0.008759   \n",
       "1878           0.078885              0.001754             0.001754   \n",
       "\n",
       "      quantiModPerTime  \n",
       "0             0.002846  \n",
       "1             0.037037  \n",
       "2             0.003298  \n",
       "3             0.002233  \n",
       "4             0.004651  \n",
       "...                ...  \n",
       "1874          0.006231  \n",
       "1875          0.000000  \n",
       "1876          0.003165  \n",
       "1877          0.002920  \n",
       "1878          0.002632  \n",
       "\n",
       "[1879 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a156079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = pd.read_csv('test.csv', delimiter='|')\n",
    "dataframe_test['totalScanned'] = dataframe_test['scannedLineItemsPerSecond'] * dataframe_test['totalScanTimeInSeconds']\n",
    "# avgValuePerScan:\n",
    "dataframe_test['avgTimePerScan'] = 1/ dataframe_test['scannedLineItemsPerSecond']\n",
    "dataframe_test['avgValuePerScan'] = dataframe_test['avgTimePerScan'] * dataframe_test['valuePerSecond']\n",
    "# manual feature generation - \"totalScanned\" ratios\n",
    "# withoutRegisPerPosition\n",
    "dataframe_test['withoutRegisPerPosition'] = dataframe_test['scansWithoutRegistration'] / dataframe_test['totalScanned']\n",
    "# ratio of scansWithoutRegis in totalScan\n",
    "# equivalent to lineItemVoidsPerPosition\n",
    "# Might indicate how new or ambivalent a customer is. Expected to be higher for low \"trustLevel\"\n",
    "# quantiModPerPosition\n",
    "dataframe_test['quantiModPerPosition'] = dataframe_test['quantityModifications'] / dataframe_test['totalScanned']\n",
    "# ratio of quanityMods in totalScan\n",
    "# manual feature generation - \"grandTotal\" ratios\n",
    "# lineItemVoidsPerTotal\n",
    "dataframe_test['lineItemVoidsPerTotal'] = dataframe_test['lineItemVoids'] / dataframe_test['grandTotal']\n",
    "# withoutRegisPerTotal\n",
    "dataframe_test['withoutRegisPerTotal'] = dataframe_test['scansWithoutRegistration'] / dataframe_test['grandTotal']\n",
    "# quantiModPerTotal\n",
    "dataframe_test['quantiModPerTotal'] = dataframe_test['quantityModifications'] / dataframe_test['grandTotal']\n",
    "# manual feature generation - \"totalScanTimeInSeconds\" ratios\n",
    "# lineItemVoidsPerTime\n",
    "dataframe_test['lineItemVoidsPerTime'] = dataframe_test['lineItemVoids'] / dataframe_test['totalScanTimeInSeconds']\n",
    "# withoutRegisPerTime\n",
    "dataframe_test['withoutRegisPerTime'] = dataframe_test['scansWithoutRegistration'] / dataframe_test['totalScanTimeInSeconds']\n",
    "# quantiModPerTime\n",
    "dataframe_test['quantiModPerTime'] = dataframe_test['quantityModifications'] / dataframe_test['totalScanTimeInSeconds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d530e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38a4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b676f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol=pd.read_csv('sol_dmc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bedc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78156b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e7c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test=dataframe_test.replace([np.nan,np.inf,-np.inf],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f552ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4038, 470356],\n",
       "       [    17,  23710]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic=LogisticRegression(penalty='none',max_iter=175)\n",
    "modelm=logistic.fit(X=X_base,y=y_base)\n",
    "predictions1=modelm.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f312a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[474394,      0],\n",
       "       [ 23727,      0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=XGBClassifier()\n",
    "model=xgb.fit(X=X_base,y=y_base)\n",
    "predictions=model.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f191c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[474394,      0],\n",
       "       [ 23727,      0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada=AdaBoostClassifier(learning_rate=0.95,n_estimators=100)\n",
    "model18=ada.fit(X=X_base,y=y_base)\n",
    "predictions18=model18.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictions18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "849b15a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trustLevel                   0\n",
       "totalScanTimeInSeconds       0\n",
       "grandTotal                   0\n",
       "lineItemVoids                0\n",
       "scansWithoutRegistration     0\n",
       "quantityModifications        0\n",
       "scannedLineItemsPerSecond    0\n",
       "valuePerSecond               0\n",
       "lineItemVoidsPerPosition     0\n",
       "totalScanned                 0\n",
       "avgTimePerScan               0\n",
       "avgValuePerScan              0\n",
       "withoutRegisPerPosition      0\n",
       "quantiModPerPosition         0\n",
       "lineItemVoidsPerTotal        0\n",
       "withoutRegisPerTotal         0\n",
       "quantiModPerTotal            0\n",
       "lineItemVoidsPerTime         0\n",
       "withoutRegisPerTime          0\n",
       "quantiModPerTime             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f6a8f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemVoids',\n",
       "       'scansWithoutRegistration', 'quantityModifications',\n",
       "       'scannedLineItemsPerSecond', 'valuePerSecond',\n",
       "       'lineItemVoidsPerPosition', 'totalScanned', 'avgTimePerScan',\n",
       "       'avgValuePerScan', 'withoutRegisPerPosition', 'quantiModPerPosition',\n",
       "       'lineItemVoidsPerTotal', 'withoutRegisPerTotal', 'quantiModPerTotal',\n",
       "       'lineItemVoidsPerTime', 'withoutRegisPerTime', 'quantiModPerTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "491d4db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trustLevel                   498121\n",
       "totalScanTimeInSeconds       498121\n",
       "grandTotal                   498121\n",
       "lineItemVoids                498121\n",
       "scansWithoutRegistration     498121\n",
       "quantityModifications        498121\n",
       "scannedLineItemsPerSecond    498121\n",
       "valuePerSecond               498121\n",
       "lineItemVoidsPerPosition     498121\n",
       "totalScanned                 498121\n",
       "avgTimePerScan               498121\n",
       "avgValuePerScan              498121\n",
       "withoutRegisPerPosition      498121\n",
       "quantiModPerPosition         498121\n",
       "lineItemVoidsPerTotal        498121\n",
       "withoutRegisPerTotal         498121\n",
       "quantiModPerTotal            498121\n",
       "lineItemVoidsPerTime         498121\n",
       "withoutRegisPerTime          498121\n",
       "quantiModPerTime             498121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(dataframe_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0f277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0d8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36e15367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[474394,      0],\n",
       "       [ 23727,      0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random=RandomForestClassifier(n_estimators= 75,\n",
    " min_samples_split= 2,\n",
    " min_samples_leaf= 1,\n",
    " max_features= 'auto')\n",
    "clf=random.fit(X_base,y_base)\n",
    "predict=clf.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c324441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_base1=sc.fit_transform(X_base)\n",
    "dataframe_test1=sc.fit_transform(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "727698a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471312,   3082],\n",
       "       [  2116,  21611]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv=SVC(C=100, gamma=0.001, kernel='rbf')\n",
    "svc=sv.fit(X_base1,y_base)\n",
    "pred=svc.predict(dataframe_test1)\n",
    "confusion_matrix(df_sol['fraud'],pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22040178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[470649,   3745],\n",
       "       [  1406,  22321]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv1=SVC(C=800, gamma=0.0009, kernel='rbf')\n",
    "svc1=sv1.fit(X_base1,y_base)\n",
    "pred11=svc1.predict(dataframe_test1)\n",
    "confusion_matrix(df_sol['fraud'],pred11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45ea1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voter=pd.DataFrame()\n",
    "df_voter['svc']=pred11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede8321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d666ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.1s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.947 total time=   0.1s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.952 total time=   0.1s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.952 total time=   0.2s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.952 total time=   0.2s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.949 total time=   0.2s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.949 total time=   0.2s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.987 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.971 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.963 total time=   0.1s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.957 total time=   0.1s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.963 total time=   0.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.960 total time=   0.1s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.955 total time=   0.1s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.987 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.987 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.995 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.963 total time=   0.2s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.957 total time=   0.2s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.963 total time=   0.2s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.960 total time=   0.2s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.955 total time=   0.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.995 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.997 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.987 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.995 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.995 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.963 total time=   0.1s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.957 total time=   0.2s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.963 total time=   0.2s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.960 total time=   0.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.955 total time=   0.1s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.976 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.995 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.981 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.987 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.997 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.987 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.989 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.997 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.984 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.992 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.995 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.995 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.989 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_base, y_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30391e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "378a10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:31:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'min_child_weight': 3}, 0.9985620389000671)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,10,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de7962f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.16}, 0.9986666666666666)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'learning_rate':[i/100.0 for i in range(1,100)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb56d29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:33:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 250}, 0.9987525150905432)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'n_estimators':[i for i in range(100,500,50)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b985ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:33:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'scale_pos_weight': 1}, 0.9987525150905432)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'scale_pos_weight':[i for i in range(1,25)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e22422f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:33:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[474394,      0],\n",
       "       [ 23727,      0]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying XGB after hyper-parameter tuning\n",
    "xgbnew=XGBClassifier(learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=5, scale_pos_weight=20, seed=27)\n",
    "modelnew=xgbnew.fit(X=X_base,y=y_base)\n",
    "predictionsnew=modelnew.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictionsnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4294f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voter['logistic']=predictions1\n",
    "df_voter['ada']=predictions18\n",
    "df_voter['xgb']=predictionsnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be5e5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "048d8c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498121"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b75e1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[]\n",
    "naya_list=[]\n",
    "imp_list=[]\n",
    "for row in range(len(dataframe_test)):\n",
    "    for column in range(4):\n",
    "        arr.append(df_voter.loc[row][column])\n",
    "    imp_list.append(1.2*arr[0]+arr[1]+1.1*arr[2]+1.1*arr[3])    \n",
    "    if imp_list[0]>2.4:\n",
    "        naya_list.append(1)\n",
    "    else:\n",
    "        naya_list.append(0)\n",
    "    imp_list=[]\n",
    "    arr=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f77f03ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...],\n",
       "         trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       " 0                4                     467       88.48              4   \n",
       " 1                3                    1004       58.99              7   \n",
       " 2                1                     162       14.00              4   \n",
       " 3                5                     532       84.79              9   \n",
       " 4                5                     890       42.16              4   \n",
       " ...            ...                     ...         ...            ...   \n",
       " 498116           4                     783       59.10              2   \n",
       " 498117           1                     278       98.90              9   \n",
       " 498118           3                     300        5.41              6   \n",
       " 498119           2                    1524       33.97              2   \n",
       " 498120           3                    1456       56.97             11   \n",
       " \n",
       "         scansWithoutRegistration  quantityModifications  \\\n",
       " 0                              8                      4   \n",
       " 1                              6                      1   \n",
       " 2                              5                      4   \n",
       " 3                              3                      4   \n",
       " 4                              0                      0   \n",
       " ...                          ...                    ...   \n",
       " 498116                         2                      0   \n",
       " 498117                         5                      4   \n",
       " 498118                         6                      4   \n",
       " 498119                         5                      3   \n",
       " 498120                         7                      2   \n",
       " \n",
       "         scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       " 0                        0.014989        0.189465                  0.571429   \n",
       " 1                        0.026892        0.058755                  0.259259   \n",
       " 2                        0.006173        0.086420                  4.000000   \n",
       " 3                        0.026316        0.159380                  0.642857   \n",
       " 4                        0.021348        0.047371                  0.210526   \n",
       " ...                           ...             ...                       ...   \n",
       " 498116                   0.012771        0.075479                  0.200000   \n",
       " 498117                   0.050360        0.355755                  0.642857   \n",
       " 498118                   0.030000        0.018033                  0.666667   \n",
       " 498119                   0.005906        0.022290                  0.222222   \n",
       " 498120                   0.019231        0.039128                  0.392857   \n",
       " \n",
       "         totalScanned  avgTimePerScan  avgValuePerScan  \\\n",
       " 0                7.0       66.714286        12.640000   \n",
       " 1               27.0       37.185185         2.184815   \n",
       " 2                1.0      162.000000        14.000000   \n",
       " 3               14.0       38.000000         6.056429   \n",
       " 4               19.0       46.842105         2.218947   \n",
       " ...              ...             ...              ...   \n",
       " 498116          10.0       78.300000         5.910000   \n",
       " 498117          14.0       19.857143         7.064286   \n",
       " 498118           9.0       33.333333         0.601111   \n",
       " 498119           9.0      169.333333         3.774444   \n",
       " 498120          28.0       52.000000         2.034643   \n",
       " \n",
       "         withoutRegisPerPosition  quantiModPerPosition  lineItemVoidsPerTotal  \\\n",
       " 0                      1.142857              0.571429               0.045208   \n",
       " 1                      0.222222              0.037037               0.118664   \n",
       " 2                      5.000000              4.000000               0.285714   \n",
       " 3                      0.214286              0.285714               0.106145   \n",
       " 4                      0.000000              0.000000               0.094877   \n",
       " ...                         ...                   ...                    ...   \n",
       " 498116                 0.200000              0.000000               0.033841   \n",
       " 498117                 0.357143              0.285714               0.091001   \n",
       " 498118                 0.666667              0.444444               1.109057   \n",
       " 498119                 0.555556              0.333333               0.058875   \n",
       " 498120                 0.250000              0.071429               0.193084   \n",
       " \n",
       "         withoutRegisPerTotal  quantiModPerTotal  lineItemVoidsPerTime  \\\n",
       " 0                   0.090416           0.045208              0.008565   \n",
       " 1                   0.101712           0.016952              0.006972   \n",
       " 2                   0.357143           0.285714              0.024691   \n",
       " 3                   0.035382           0.047175              0.016917   \n",
       " 4                   0.000000           0.000000              0.004494   \n",
       " ...                      ...                ...                   ...   \n",
       " 498116              0.033841           0.000000              0.002554   \n",
       " 498117              0.050556           0.040445              0.032374   \n",
       " 498118              1.109057           0.739372              0.020000   \n",
       " 498119              0.147189           0.088313              0.001312   \n",
       " 498120              0.122872           0.035106              0.007555   \n",
       " \n",
       "         withoutRegisPerTime  quantiModPerTime  \n",
       " 0                  0.017131          0.008565  \n",
       " 1                  0.005976          0.000996  \n",
       " 2                  0.030864          0.024691  \n",
       " 3                  0.005639          0.007519  \n",
       " 4                  0.000000          0.000000  \n",
       " ...                     ...               ...  \n",
       " 498116             0.002554          0.000000  \n",
       " 498117             0.017986          0.014388  \n",
       " 498118             0.020000          0.013333  \n",
       " 498119             0.003281          0.001969  \n",
       " 498120             0.004808          0.001374  \n",
       " \n",
       " [498121 rows x 20 columns])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naya_list,dataframe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a2535f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[474394,      0],\n",
       "       [ 23727,      0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_sol['fraud'],pd.Series(naya_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f70be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "982812b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98    474394\n",
      "           1       0.00      0.00      0.00     23727\n",
      "\n",
      "    accuracy                           0.95    498121\n",
      "   macro avg       0.48      0.50      0.49    498121\n",
      "weighted avg       0.91      0.95      0.93    498121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_sol['fraud'],predictionsnew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9a40fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB w/ PCA & featuretools & SelectKBest on data w/ additional manual features generated: 0.9856382978723405\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components=8)))\n",
    "features.append(('select_best', SelectKBest(k=4)))\n",
    "feature_union = FeatureUnion(features)\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "estimators.append(('xgb', XGBClassifier(learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=5, scale_pos_weight=20, seed=27)))\n",
    "\n",
    "xgb_af = Pipeline(estimators)\n",
    "\n",
    "print('XGB w/ PCA & featuretools & SelectKBest on data w/ additional manual features generated: {}'.format(np.mean(cross_validate(xgb_af, X_base, y=y_base, cv=cv)['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1435413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgc_af=xgb_af.fit(X_base,y_base)\n",
    "pf=xgc_af.predict(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6523e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 20)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baec186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[474394,      0],\n",
       "       [ 23727,      0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_sol['fraud'],pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b85bca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "def upsample_SMOTE(X, y, ratio=0.08):\n",
    "    sm = SMOTE(random_state=23, sampling_strategy=ratio)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X, y)\n",
    "    print(len(X_train_sm), len(y_train_sm))\n",
    "    return X_train_sm, y_train_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e11aa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2218 2218\n"
     ]
    }
   ],
   "source": [
    "X_train_sm,y_train_sm=upsample_SMOTE(X_base, y_base, ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ace95c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm=pd.DataFrame(X_train_sm)\n",
    "y_train_sm=pd.DataFrame(y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccf3f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=X_train_sm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f3804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af109001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pca] >Processing dataframe..\n",
      "[pca] >The PCA reduction is performed on the [20] columns of the input dataframe.\n",
      "[pca] >Fitting using PCA..\n",
      "[pca] >Computing loadings and PCs..\n",
      "[pca] >Computing explained variance..\n",
      "[pca] >Outlier detection using Hotelling T2 test with alpha=[0.05] and n_components=[15]\n",
      "[pca] >Outlier detection using SPE/DmodX with n_std=[2]\n"
     ]
    }
   ],
   "source": [
    "import pca\n",
    "from pca import pca\n",
    "model = pca(n_components=15)\n",
    "# Fit transform\n",
    "out = model.fit_transform(X_train_sm)\n",
    "\n",
    "# Print the top features. The results show that f1 is best, followed by f2 etc\n",
    "feature=list(out['topfeat']['feature'][:15])\n",
    "feature=list(set(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7477c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(my_model.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "709d8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=X_train_sm[feture]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b47b920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935189</td>\n",
       "      <td>0.229898</td>\n",
       "      <td>0.132567</td>\n",
       "      <td>0.443466</td>\n",
       "      <td>-1.562415</td>\n",
       "      <td>0.280068</td>\n",
       "      <td>-0.109983</td>\n",
       "      <td>-0.120670</td>\n",
       "      <td>-0.379855</td>\n",
       "      <td>1.564236</td>\n",
       "      <td>-0.565402</td>\n",
       "      <td>-0.381170</td>\n",
       "      <td>-0.038577</td>\n",
       "      <td>-0.075657</td>\n",
       "      <td>-0.119692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.235121</td>\n",
       "      <td>-1.554996</td>\n",
       "      <td>-0.812391</td>\n",
       "      <td>-0.136202</td>\n",
       "      <td>-0.925241</td>\n",
       "      <td>0.870031</td>\n",
       "      <td>0.256761</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>-0.292611</td>\n",
       "      <td>-0.158893</td>\n",
       "      <td>-0.446827</td>\n",
       "      <td>-0.108772</td>\n",
       "      <td>-0.036293</td>\n",
       "      <td>-0.021889</td>\n",
       "      <td>0.179045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.235121</td>\n",
       "      <td>1.101590</td>\n",
       "      <td>0.390409</td>\n",
       "      <td>-0.715870</td>\n",
       "      <td>1.623453</td>\n",
       "      <td>1.459994</td>\n",
       "      <td>-0.178001</td>\n",
       "      <td>-0.129443</td>\n",
       "      <td>-0.387851</td>\n",
       "      <td>-0.273769</td>\n",
       "      <td>0.073080</td>\n",
       "      <td>0.039036</td>\n",
       "      <td>-0.041901</td>\n",
       "      <td>-0.060594</td>\n",
       "      <td>-0.154817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.520344</td>\n",
       "      <td>1.620455</td>\n",
       "      <td>1.432490</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>-0.288068</td>\n",
       "      <td>0.870031</td>\n",
       "      <td>-0.150646</td>\n",
       "      <td>-0.120957</td>\n",
       "      <td>-0.353867</td>\n",
       "      <td>1.564236</td>\n",
       "      <td>-0.450915</td>\n",
       "      <td>-0.329635</td>\n",
       "      <td>-0.040300</td>\n",
       "      <td>-0.082432</td>\n",
       "      <td>-0.136074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.935189</td>\n",
       "      <td>-0.947453</td>\n",
       "      <td>1.059898</td>\n",
       "      <td>-0.715870</td>\n",
       "      <td>0.667693</td>\n",
       "      <td>-0.309895</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>-0.009777</td>\n",
       "      <td>-0.478031</td>\n",
       "      <td>1.334485</td>\n",
       "      <td>-0.350210</td>\n",
       "      <td>-0.425070</td>\n",
       "      <td>-0.042379</td>\n",
       "      <td>-0.093498</td>\n",
       "      <td>-0.117166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.935189  0.229898  0.132567  0.443466 -1.562415  0.280068 -0.109983   \n",
       "1 -0.235121 -1.554996 -0.812391 -0.136202 -0.925241  0.870031  0.256761   \n",
       "2 -0.235121  1.101590  0.390409 -0.715870  1.623453  1.459994 -0.178001   \n",
       "3  1.520344  1.620455  1.432490  0.733300 -0.288068  0.870031 -0.150646   \n",
       "4  0.935189 -0.947453  1.059898 -0.715870  0.667693 -0.309895  0.016712   \n",
       "\n",
       "         7         8         9         12        13        14        16  \\\n",
       "0 -0.120670 -0.379855  1.564236 -0.565402 -0.381170 -0.038577 -0.075657   \n",
       "1  0.041543 -0.292611 -0.158893 -0.446827 -0.108772 -0.036293 -0.021889   \n",
       "2 -0.129443 -0.387851 -0.273769  0.073080  0.039036 -0.041901 -0.060594   \n",
       "3 -0.120957 -0.353867  1.564236 -0.450915 -0.329635 -0.040300 -0.082432   \n",
       "4 -0.009777 -0.478031  1.334485 -0.350210 -0.425070 -0.042379 -0.093498   \n",
       "\n",
       "         17  \n",
       "0 -0.119692  \n",
       "1  0.179045  \n",
       "2 -0.154817  \n",
       "3 -0.136074  \n",
       "4 -0.117166  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89456b2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 16, 17], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Anuj kadam\\OneDrive\\Desktop\\self-checkout-fraud-detection\\selfCheckoutResearch.ipynb Cell 57'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Anuj%20kadam/OneDrive/Desktop/self-checkout-fraud-detection/selfCheckoutResearch.ipynb#ch0000056?line=0'>1</a>\u001b[0m df2\u001b[39m=\u001b[39mdataframe_test[feature]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anuj%20kadam/OneDrive/Desktop/self-checkout-fraud-detection/selfCheckoutResearch.ipynb#ch0000056?line=1'>2</a>\u001b[0m xgbnew1\u001b[39m=\u001b[39mXGBClassifier(learning_rate \u001b[39m=\u001b[39m\u001b[39m0.16\u001b[39m, n_estimators\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,reg_alpha\u001b[39m=\u001b[39m\u001b[39m1e-05\u001b[39m,min_child_weight\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, subsample\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, colsample_bytree\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m,objective\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m, nthread\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scale_pos_weight\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39m27\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Anuj%20kadam/OneDrive/Desktop/self-checkout-fraud-detection/selfCheckoutResearch.ipynb#ch0000056?line=2'>3</a>\u001b[0m modelnew1\u001b[39m=\u001b[39mxgbnew1\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX_train_sm,y\u001b[39m=\u001b[39my_train_sm)\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/frame.py?line=3508'>3509</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/frame.py?line=3509'>3510</a>\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> <a href='file:///c%3A/Python/lib/site-packages/pandas/core/frame.py?line=3510'>3511</a>\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/frame.py?line=3512'>3513</a>\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/frame.py?line=3513'>3514</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5778'>5779</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5779'>5780</a>\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5781'>5782</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5783'>5784</a>\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5784'>5785</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5785'>5786</a>\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5839'>5840</a>\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5840'>5841</a>\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5841'>5842</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5843'>5844</a>\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   <a href='file:///c%3A/Python/lib/site-packages/pandas/core/indexes/base.py?line=5844'>5845</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 16, 17], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df2=dataframe_test[feature]\n",
    "xgbnew1=XGBClassifier(learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,objective= 'binary:logistic', nthread=5, scale_pos_weight=20, seed=27)\n",
    "modelnew1=xgbnew1.fit(X=X_train_sm,y=y_train_sm)\n",
    "predictionsnew1=modelnew1.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictionsnew1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76d030d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[474297,     97],\n",
       "       [ 18087,   5640]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf8 = MLPClassifier(random_state=1, max_iter=100,hidden_layer_sizes=(90,), activation='relu',solver='adam').fit(X_base, y_base)\n",
    "cf=clf8.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a1ce94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['svc', 'logistic', 'ada', 'xgb'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78e9f7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[470649   3745]\n",
      " [  1406  22321]]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "[[470601   3793]\n",
      " [  3623  20104]]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "[[471734   2660]\n",
      " [  2684  21043]]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "[[469575   4819]\n",
      " [  2561  21166]]\n",
      "-----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#finally lets see the best model\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['svc']))\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['logistic']))\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['ada']))\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['xgb']))\n",
    "print('-----------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270e7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_pkl', 'wb') as files:\n",
    "    pickle.dump(svc1, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9911ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
